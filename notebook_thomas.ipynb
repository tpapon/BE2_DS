{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2653bf19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from collections import defaultdict, Counter\n",
    "from typing import Dict, List, Tuple\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For embeddings and similarity computation\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    print(\"Required libraries imported successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"Missing library: {e}\")\n",
    "    print(\"Please install with: pip install sentence-transformers scikit-learn networkx\")\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15048de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import find, csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.linalg import norm\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "# des options permettent de limiter (ou non) le nombre de lignes/colonnes affichées\n",
    "# par exemple :\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "# cette fonction permet d'afficher une \"jolie\" représentation du vecteur v\n",
    "# ARGS :\n",
    "#   v : le vecteur à afficher (par ex. une ligne de la matrice X)\n",
    "#   features : le vocabulaire\n",
    "#   top_n : le nombre de mots maximum à afficher\n",
    "def print_feats(v, features, top_n = 30):\n",
    "    _, ids, values = find(v)\n",
    "    feats = [(ids[i], values[i], features[ids[i]]) for i in range(len(list(ids)))]\n",
    "    top_feats = sorted(feats, key=lambda x: x[1], reverse=True)[0:top_n]\n",
    "    return pd.DataFrame({\"word\" : [t[2] for t in top_feats], \"value\": [t[1] for t in top_feats]})   \n",
    "\n",
    "# fonction qui permet d'afficher plusieurs tables pandas côte à côte (c'est cadeau)\n",
    "def display_side_by_side(dfs:list, captions:list):\n",
    "    \"\"\"Display tables side by side to save vertical space\n",
    "    Input:\n",
    "        dfs: list of pandas.DataFrame\n",
    "        captions: list of table captions\n",
    "    \"\"\"\n",
    "    output = \"\"\n",
    "    combined = dict(zip(captions, dfs))\n",
    "    for caption, df in combined.items():\n",
    "        output += df.style.set_table_attributes(\"style='display:inline'\").set_caption(caption)._repr_html_()\n",
    "        output += \"&emsp;\"\n",
    "        #output += \"\\xa0\\xa0\\xa0\"\n",
    "    display(HTML(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcecf5c0",
   "metadata": {},
   "source": [
    "# 1. Chargement et prise en main des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a74280e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_corpus(file_path: str) -> Dict[str, Dict]:\n",
    "    \"\"\"\n",
    "    Load corpus data from a JSONL file.\n",
    "    Returns a dictionary mapping document IDs to their associated metadata.\n",
    "    \"\"\"\n",
    "    corpus = {}\n",
    "    \n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if line.strip():  # skip empty lines\n",
    "                doc = json.loads(line)\n",
    "                doc_id = doc.get(\"_id\")\n",
    "                if doc_id is not None:\n",
    "                    corpus[doc_id] = doc\n",
    "                    \n",
    "    return corpus\n",
    "\n",
    "\n",
    "def load_queries(file_path: str) -> Dict[str, Dict]:\n",
    "    \"\"\"\n",
    "    Load query data from a JSONL file.\n",
    "    Returns a dictionary mapping query IDs to query metadata.\n",
    "    \"\"\"\n",
    "    queries = {}\n",
    "    \n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                q = json.loads(line)\n",
    "                q_id = q.get(\"_id\")\n",
    "                if q_id is not None:\n",
    "                    queries[q_id] = q\n",
    "                    \n",
    "    return queries\n",
    "\n",
    "\n",
    "def load_qrels(file_path: str) -> Dict[str, Dict[str, int]]:\n",
    "    \"\"\"\n",
    "    Load relevance judgments from a TSV file.\n",
    "    Returns a dictionary:\n",
    "        { query_id : { candidate_id : relevance_score } }\n",
    "    \"\"\"\n",
    "    qrels = {}\n",
    "    \n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\"\\t\")\n",
    "            if len(parts) != 3:\n",
    "                continue  # skip malformed lines\n",
    "            \n",
    "            q_id, c_id, score = parts\n",
    "            score = int(score)\n",
    "\n",
    "            if q_id not in qrels:\n",
    "                qrels[q_id] = {}\n",
    "            qrels[q_id][c_id] = score\n",
    "    \n",
    "    return qrels\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
